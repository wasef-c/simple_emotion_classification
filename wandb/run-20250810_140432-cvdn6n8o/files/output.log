ğŸš€ Starting experiment: Curr+Scaling
ğŸ“Š Evaluation Mode: CROSS_CORPUS
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPI_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
ğŸ” Feature shape for MSPI: torch.Size([768])
âœ… Loaded 7798 samples from MSPI
ğŸ“Š MSPI Sessions:
   Session 1: 1108 samples
   Session 2: 1547 samples
   Session 3: 1431 samples
   Session 4: 1143 samples
   Session 5: 1518 samples
   Session 6: 518 samples
   Session 7: 533 samples
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/IEMO_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
ğŸ” Feature shape for IEMO: torch.Size([768])
âœ… Loaded 4490 samples from IEMO
ğŸ“Š IEMO Sessions:
   Session None: 4490 samples
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPP_Emotion2vec_filtered' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
ğŸ” Feature shape for MSPP: torch.Size([768])
âœ… Loaded 80941 samples from MSPP
ğŸ“Š MSPP Sessions:
   Session None: 80941 samples
ğŸš€ Training: MSPI -> [IEMO, MSPP]
ğŸ”§ Using device: cuda
ğŸ“š Curriculum Learning: Enabled
ğŸ“Š Cross-Corpus Only Mode: Train=80%, Val=20%
ğŸ“ˆ Training samples: 6239
ğŸ“‹ Validation samples: 1559
ğŸ¯ Test datasets: IEMO, MSPP
ğŸ” Using input_dim: 768 (detected from MSPI)
<config.Config object at 0x768b90896ef0>
   Epoch 1: Using 1972/6239 samples (0.32)
âŒ Experiment Curr+Scaling failed: mat1 and mat2 shapes cannot be multiplied (1x48 and 768x1024)
ğŸ” Full traceback:
Traceback (most recent call last):
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 122, in run_all_experiments_from_yaml
    result = run_experiment(config)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 210, in run_experiment
    results = run_cross_corpus_evaluation(config, train_dataset, test_datasets)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 664, in run_cross_corpus_evaluation
    train_loss, train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 419, in train_epoch
    logits = model(features)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/model.py", line 30, in forward
    logits = self.classifier(x)  # (batch_size, num_classes)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 244, in forward
    input = module(input)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x48 and 768x1024)


============================================================
ğŸ§ª EXPERIMENT 2/3: No_Curriculum
============================================================
ğŸ§ª Running experiment: No_Curriculum
âš ï¸  Unknown config parameter: class_weights
[34m[1mwandb[0m: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
ğŸš€ Starting experiment: No_Curriculum
ğŸ“Š Evaluation Mode: CROSS_CORPUS
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPI_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
ğŸ” Feature shape for MSPI: torch.Size([768])
âœ… Loaded 7798 samples from MSPI
ğŸ“Š MSPI Sessions:
   Session 1: 1108 samples
   Session 2: 1547 samples
   Session 3: 1431 samples
   Session 4: 1143 samples
   Session 5: 1518 samples
   Session 6: 518 samples
   Session 7: 533 samples
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/IEMO_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
ğŸ” Feature shape for IEMO: torch.Size([768])
âœ… Loaded 4490 samples from IEMO
ğŸ“Š IEMO Sessions:
   Session None: 4490 samples
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPP_Emotion2vec_filtered' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
ğŸ” Feature shape for MSPP: torch.Size([768])
âœ… Loaded 80941 samples from MSPP
ğŸ“Š MSPP Sessions:
   Session None: 80941 samples
ğŸš€ Training: MSPI -> [IEMO, MSPP]
ğŸ”§ Using device: cuda
ğŸ“š Curriculum Learning: Disabled
ğŸ“Š Cross-Corpus Only Mode: Train=80%, Val=20%
ğŸ“ˆ Training samples: 6239
ğŸ“‹ Validation samples: 1559
ğŸ¯ Test datasets: IEMO, MSPP
ğŸ” Using input_dim: 768 (detected from MSPI)
<config.Config object at 0x768b5135ad70>
   Epoch 1: Curriculum complete, using all training data
âŒ Experiment No_Curriculum failed: mat1 and mat2 shapes cannot be multiplied (1x48 and 768x1024)
ğŸ” Full traceback:
Traceback (most recent call last):
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 122, in run_all_experiments_from_yaml
    result = run_experiment(config)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 210, in run_experiment
    results = run_cross_corpus_evaluation(config, train_dataset, test_datasets)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 664, in run_cross_corpus_evaluation
    train_loss, train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 419, in train_epoch
    logits = model(features)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/model.py", line 30, in forward
    logits = self.classifier(x)  # (batch_size, num_classes)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 244, in forward
    input = module(input)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x48 and 768x1024)


============================================================
ğŸ§ª EXPERIMENT 3/3: Linear_Pacing
============================================================
ğŸ§ª Running experiment: Linear_Pacing
âš ï¸  Unknown config parameter: class_weights
[34m[1mwandb[0m: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
ğŸš€ Starting experiment: Linear_Pacing
ğŸ“Š Evaluation Mode: CROSS_CORPUS
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPI_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
ğŸ” Feature shape for MSPI: torch.Size([768])
âœ… Loaded 7798 samples from MSPI
ğŸ“Š MSPI Sessions:
   Session 1: 1108 samples
   Session 2: 1547 samples
   Session 3: 1431 samples
   Session 4: 1143 samples
   Session 5: 1518 samples
   Session 6: 518 samples
   Session 7: 533 samples
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/IEMO_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
ğŸ” Feature shape for IEMO: torch.Size([768])
âœ… Loaded 4490 samples from IEMO
ğŸ“Š IEMO Sessions:
   Session None: 4490 samples
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPP_Emotion2vec_filtered' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
ğŸ” Feature shape for MSPP: torch.Size([768])
âœ… Loaded 80941 samples from MSPP
ğŸ“Š MSPP Sessions:
   Session None: 80941 samples
ğŸš€ Training: MSPI -> [IEMO, MSPP]
ğŸ”§ Using device: cuda
ğŸ“š Curriculum Learning: Enabled
ğŸ“Š Cross-Corpus Only Mode: Train=80%, Val=20%
ğŸ“ˆ Training samples: 6239
ğŸ“‹ Validation samples: 1559
ğŸ¯ Test datasets: IEMO, MSPP
ğŸ” Using input_dim: 768 (detected from MSPI)
<config.Config object at 0x768bc562af80>
   Epoch 1: Using 623/6239 samples (0.10)
âŒ Experiment Linear_Pacing failed: mat1 and mat2 shapes cannot be multiplied (1x48 and 768x1024)
ğŸ” Full traceback:
Traceback (most recent call last):
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 122, in run_all_experiments_from_yaml
    result = run_experiment(config)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 210, in run_experiment
    results = run_cross_corpus_evaluation(config, train_dataset, test_datasets)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 664, in run_cross_corpus_evaluation
    train_loss, train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 419, in train_epoch
    logits = model(features)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/model.py", line 30, in forward
    logits = self.classifier(x)  # (batch_size, num_classes)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 244, in forward
    input = module(input)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x48 and 768x1024)


============================================================
ğŸ“Š EXPERIMENT SUMMARY
============================================================
âœ… Completed: 0
âŒ Failed: 3
