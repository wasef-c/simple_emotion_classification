üöÄ Starting experiment: Curr+Scaling
üìä Evaluation Mode: CROSS_CORPUS
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPI_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
üîç Feature shape for MSPI: torch.Size([768])
‚úÖ Loaded 7798 samples from MSPI
üìä MSPI Sessions:
   Session 1: 1108 samples
   Session 2: 1547 samples
   Session 3: 1431 samples
   Session 4: 1143 samples
   Session 5: 1518 samples
   Session 6: 518 samples
   Session 7: 533 samples
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/IEMO_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
üîç Feature shape for IEMO: torch.Size([768])
‚úÖ Loaded 4490 samples from IEMO
üìä IEMO Sessions:
   Session None: 4490 samples
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPP_Emotion2vec_filtered' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
üîç Feature shape for MSPP: torch.Size([768])
‚úÖ Loaded 80941 samples from MSPP
üìä MSPP Sessions:
   Session None: 80941 samples
üöÄ Training: MSPI -> [IEMO, MSPP]
üîß Using device: cuda
üìö Curriculum Learning: Enabled
üìä Cross-Corpus Only Mode: Train=80%, Val=20%
üìà Training samples: 6239
üìã Validation samples: 1559
üéØ Test datasets: IEMO, MSPP
üîç Using input_dim: 768 (detected from MSPI)
<config.Config object at 0x7e8b7f176ec0>
   Epoch 1: Using 1972/6239 samples (0.32)
‚ùå Experiment Curr+Scaling failed: mat1 and mat2 shapes cannot be multiplied (1x48 and 768x1024)
üîç Full traceback:
Traceback (most recent call last):
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 122, in run_all_experiments_from_yaml
    result = run_experiment(config)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 210, in run_experiment
    results = run_cross_corpus_evaluation(config, train_dataset, test_datasets)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 664, in run_cross_corpus_evaluation
    train_loss, train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 419, in train_epoch
    logits = model(features)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/model.py", line 30, in forward
    logits = self.classifier(x)  # (batch_size, num_classes)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 244, in forward
    input = module(input)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x48 and 768x1024)


============================================================
üß™ EXPERIMENT 2/3: No_Curriculum
============================================================
üß™ Running experiment: No_Curriculum
‚ö†Ô∏è  Unknown config parameter: class_weights
[34m[1mwandb[0m: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
üöÄ Starting experiment: No_Curriculum
üìä Evaluation Mode: CROSS_CORPUS
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPI_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
üîç Feature shape for MSPI: torch.Size([768])
Traceback (most recent call last):
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 759, in <module>
    main(args.config, experiment_id, args.all)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 735, in main
    return run_all_experiments_from_yaml(config_path)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 122, in run_all_experiments_from_yaml
    result = run_experiment(config)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 170, in run_experiment
    train_dataset = SimpleEmotionDataset("MSPI", config=config, Train=True)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 323, in __init__
    features = torch.tensor(item["emotion2vec_features"][0]["feats"], dtype=torch.float32)
KeyboardInterrupt
