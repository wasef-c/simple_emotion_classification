üöÄ Starting experiment: Curr+Scaling
üìä Evaluation Mode: CROSS_CORPUS
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPI_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
‚úÖ Loaded 7798 samples from MSPI
üìä MSPI Sessions:
   Session 1: 1108 samples
   Session 2: 1547 samples
   Session 3: 1431 samples
   Session 4: 1143 samples
   Session 5: 1518 samples
   Session 6: 518 samples
   Session 7: 533 samples
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/IEMO_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
‚úÖ Loaded 4490 samples from IEMO
üìä IEMO Sessions:
   Session None: 4490 samples
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPP_Emotion2vec_filtered' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
‚úÖ Loaded 80941 samples from MSPP
üìä MSPP Sessions:
   Session None: 80941 samples
üöÄ Training: MSPI -> [IEMO, MSPP]
üîß Using device: cuda
üìö Curriculum Learning: Enabled
üìä Cross-Corpus Only Mode: Train=80%, Val=20%
üìà Training samples: 6239
üìã Validation samples: 1559
üéØ Test datasets: IEMO, MSPP
<config.Config object at 0x720755f5e7a0>
   Epoch 1: Using 1972/6239 samples (0.32)
‚ùå Experiment Curr+Scaling failed: mat1 and mat2 shapes cannot be multiplied (1x48 and 768x1024)
üîç Full traceback:
Traceback (most recent call last):
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 122, in run_all_experiments_from_yaml
    result = run_experiment(config)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 210, in run_experiment
    results = run_cross_corpus_evaluation(config, train_dataset, test_datasets)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 638, in run_cross_corpus_evaluation
    train_loss, train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 415, in train_epoch
    logits = model(features)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/model.py", line 30, in forward
    logits = self.classifier(x)  # (batch_size, num_classes)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 244, in forward
    input = module(input)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x48 and 768x1024)


============================================================
üß™ EXPERIMENT 2/3: No_Curriculum
============================================================
üß™ Running experiment: No_Curriculum
‚ö†Ô∏è  Unknown config parameter: class_weights
[34m[1mwandb[0m: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
üöÄ Starting experiment: No_Curriculum
üìä Evaluation Mode: CROSS_CORPUS
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'cairocode/MSPI_Emotion2Vec' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
Traceback (most recent call last):
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 733, in <module>
    main(args.config, experiment_id, args.all)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 709, in main
    return run_all_experiments_from_yaml(config_path)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 122, in run_all_experiments_from_yaml
    result = run_experiment(config)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 170, in run_experiment
    train_dataset = SimpleEmotionDataset("MSPI", config=config, Train=True)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/main.py", line 322, in __init__
    for item in self.hf_dataset:
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 2466, in __iter__
    formatted_output = format_table(
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py", line 657, in format_table
    return formatter(pa_table, query_type=query_type)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py", line 410, in __call__
    return self.format_row(pa_table)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py", line 458, in format_row
    row = self.python_arrow_extractor().extract_row(pa_table)
  File "/media/carol/Data/Documents/Emo_rec/Notebooks/emotion2vec_HAF/Version B/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py", line 143, in extract_row
    return _unnest(pa_table.to_pydict())
KeyboardInterrupt
